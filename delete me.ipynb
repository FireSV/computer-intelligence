{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM MAE: 33.65\n",
      "Neural Network MAE: 33.68\n",
      "Decision Tree MAE: 45.52\n",
      "Random Forest MAE: 34.35\n",
      "Gradient Boosting MAE: 33.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sandu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] The system cannot find the file specified\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\Users\\sandu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "        \"wmic CPU Get NumberOfCores /Format:csv\".split(),\n",
      "        capture_output=True,\n",
      "        text=True,\n",
      "    )\n",
      "  File \"c:\\Users\\sandu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 554, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 1036, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "                        pass_fds, cwd, env,\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "                        gid, gids, uid, umask,\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^\n",
      "                        start_new_session, process_group)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandu\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py\", line 1548, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "                             # no special security\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "                             cwd,\n",
      "                             ^^^^\n",
      "                             startupinfo)\n",
      "                             ^^^^^^^^^^^^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to sample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Drop 'id' as it's not a feature\n",
    "test_ids = test_df['id']\n",
    "train_df.drop(columns=['id'], inplace=True)\n",
    "test_df.drop(columns=['id'], inplace=True)\n",
    "\n",
    "# Handle missing values\n",
    "train_df.ffill(inplace=True)\n",
    "test_df.ffill(inplace=True)\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = ['Brand', 'Material', 'Size', 'Style', 'Color', 'Laptop Compartment', 'Waterproof']\n",
    "numerical_cols = [col for col in train_df.columns if col not in categorical_cols + ['Price']]\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    if col in train_df and col in test_df:\n",
    "        le = LabelEncoder()\n",
    "        train_df[col] = le.fit_transform(train_df[col].astype(str))\n",
    "        test_df[col] = le.transform(test_df[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "\n",
    "# Define features and target\n",
    "X = train_df.drop(columns=['Price'])\n",
    "y = train_df['Price']\n",
    "\n",
    "# Split training data for validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Handle missing values in numerical features\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train[numerical_cols] = imputer.fit_transform(X_train[numerical_cols])\n",
    "X_val[numerical_cols] = imputer.transform(X_val[numerical_cols])\n",
    "test_df[numerical_cols] = imputer.transform(test_df[numerical_cols])\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
    "X_val[numerical_cols] = scaler.transform(X_val[numerical_cols])\n",
    "test_df[numerical_cols] = scaler.transform(test_df[numerical_cols])\n",
    "\n",
    "# Models\n",
    "models = {\n",
    "    \"SVM\": SVR(kernel='rbf'),\n",
    "    \"Neural Network\": MLPRegressor(hidden_layer_sizes=(100,50), max_iter=500, random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(random_state=42),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Train models and evaluate\n",
    "predictions = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "    print(f\"{name} MAE: {mae:.2f}\")\n",
    "    predictions[name] = model.predict(test_df)\n",
    "\n",
    "# Clustering model (KMeans)\n",
    "kmeans = KMeans(n_clusters=5, random_state=42, n_init=10)\n",
    "kmeans.fit(X)\n",
    "kmeans_pred = kmeans.predict(test_df)\n",
    "predictions[\"KMeans\"] = kmeans_pred * (y.max() / 4)\n",
    "\n",
    "# Ensemble averaging\n",
    "ensemble_pred = np.mean(np.array(list(predictions.values())), axis=0)\n",
    "\n",
    "# Create submission file\n",
    "submission_df = pd.DataFrame({\"id\": test_ids, \"Price\": ensemble_pred})\n",
    "submission_df.to_csv(\"sample_submission.csv\", index=False)\n",
    "\n",
    "print(\"Predictions saved to sample_submission.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
